{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "czatbot_seq2seq.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggoCgDm1_gt6"
      },
      "source": [
        "# zaimportowane biblioteki\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "\n",
        "import unicodedata\n",
        "\n",
        "from io import open"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEJ0Qy4XCb70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e689a86f-9d07-4320-e12f-87f1ddf4e540"
      },
      "source": [
        "# niestety, wszystko co jest zwiazane z ML/DL musi byc robione pod gpu :(\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUvWFLe-wPGM",
        "outputId": "912f00c0-8364-47e9-fe3d-2dee8d7ff8e6"
      },
      "source": [
        "# montujemy dysk googla na własne potrzeby\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mw6l49eE-hG6",
        "outputId": "03427fbf-2cce-4c0a-f146-3635e29aa950"
      },
      "source": [
        "# https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html\n",
        "# korpus dialogów z filmów\n",
        "\n",
        "!curl -O http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 9684k  100 9684k    0     0  15.9M      0 --:--:-- --:--:-- --:--:-- 15.9M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGtXhRzV_vV8",
        "outputId": "f0ff5a8e-f34f-4c1c-df18-5f6511f9a3a8"
      },
      "source": [
        "# rozpakowujemy i czyścimy niepotrzebne pliki\n",
        "\n",
        "!unzip cornell_movie_dialogs_corpus.zip\n",
        "!mv 'cornell movie-dialogs corpus/' 'data/'\n",
        "!rm -rf '/content/__MACOSX'"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  cornell_movie_dialogs_corpus.zip\n",
            "   creating: cornell movie-dialogs corpus/\n",
            "  inflating: cornell movie-dialogs corpus/.DS_Store  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/cornell movie-dialogs corpus/\n",
            "  inflating: __MACOSX/cornell movie-dialogs corpus/._.DS_Store  \n",
            "  inflating: cornell movie-dialogs corpus/chameleons.pdf  \n",
            "  inflating: __MACOSX/cornell movie-dialogs corpus/._chameleons.pdf  \n",
            "  inflating: cornell movie-dialogs corpus/movie_characters_metadata.txt  \n",
            "  inflating: cornell movie-dialogs corpus/movie_conversations.txt  \n",
            "  inflating: cornell movie-dialogs corpus/movie_lines.txt  \n",
            "  inflating: cornell movie-dialogs corpus/movie_titles_metadata.txt  \n",
            "  inflating: cornell movie-dialogs corpus/raw_script_urls.txt  \n",
            "  inflating: cornell movie-dialogs corpus/README.txt  \n",
            "  inflating: __MACOSX/cornell movie-dialogs corpus/._README.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-5RKnmXOW1_",
        "outputId": "aec7358a-5264-4c43-f851-257acc11e1ad"
      },
      "source": [
        "!head -10 data/movie_characters_metadata.txt"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "u0 +++$+++ BIANCA +++$+++ m0 +++$+++ 10 things i hate about you +++$+++ f +++$+++ 4\n",
            "u1 +++$+++ BRUCE +++$+++ m0 +++$+++ 10 things i hate about you +++$+++ ? +++$+++ ?\n",
            "u2 +++$+++ CAMERON +++$+++ m0 +++$+++ 10 things i hate about you +++$+++ m +++$+++ 3\n",
            "u3 +++$+++ CHASTITY +++$+++ m0 +++$+++ 10 things i hate about you +++$+++ ? +++$+++ ?\n",
            "u4 +++$+++ JOEY +++$+++ m0 +++$+++ 10 things i hate about you +++$+++ m +++$+++ 6\n",
            "u5 +++$+++ KAT +++$+++ m0 +++$+++ 10 things i hate about you +++$+++ f +++$+++ 2\n",
            "u6 +++$+++ MANDELLA +++$+++ m0 +++$+++ 10 things i hate about you +++$+++ f +++$+++ 7\n",
            "u7 +++$+++ MICHAEL +++$+++ m0 +++$+++ 10 things i hate about you +++$+++ m +++$+++ 5\n",
            "u8 +++$+++ MISS PERKY +++$+++ m0 +++$+++ 10 things i hate about you +++$+++ ? +++$+++ ?\n",
            "u9 +++$+++ PATRICK +++$+++ m0 +++$+++ 10 things i hate about you +++$+++ m +++$+++ 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMU6fk2KSVkt",
        "outputId": "46e42f42-b949-4c7f-f99f-3ab9053cc025"
      },
      "source": [
        "!head -10 data/movie_conversations.txt"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L271', 'L272', 'L273', 'L274', 'L275']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L276', 'L277']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L280', 'L281']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L363', 'L364']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L365', 'L366']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRz_Pn-HSh8H",
        "outputId": "a9c8da7b-2c8d-435b-8fe9-920becc791a0"
      },
      "source": [
        "!head -10 data/movie_lines.txt"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n",
            "L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\n",
            "L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\n",
            "L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\n",
            "L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\n",
            "L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\n",
            "L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\n",
            "L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\n",
            "L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I'm kidding.  You know how sometimes you just become this \"persona\"?  And you don't know how to quit?\n",
            "L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV3kWNq-_m6-"
      },
      "source": [
        "def load_lines(file_name):\n",
        "  lines = {}\n",
        "  \n",
        "  with open(file_name, 'r', encoding='iso-8859-1') as f:\n",
        "    for line in f:\n",
        "      values = line.split(' +++$+++ ')\n",
        "      line = {}\n",
        "      \n",
        "      for i, field in enumerate(['line_id', 'characted_id', 'movie_id', 'character', 'text']):\n",
        "        line[field] = values[i]\n",
        "        \n",
        "      lines[line['line_id']] = line\n",
        "\n",
        "  return lines"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4M6gAn70i3tI",
        "outputId": "bd33080f-94b1-49f0-a95f-d573fa5331d2"
      },
      "source": [
        "lines = load_lines('data/movie_lines.txt')\n",
        "list(lines.items())[:5]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('L1045',\n",
              "  {'characted_id': 'u0',\n",
              "   'character': 'BIANCA',\n",
              "   'line_id': 'L1045',\n",
              "   'movie_id': 'm0',\n",
              "   'text': 'They do not!\\n'}),\n",
              " ('L1044',\n",
              "  {'characted_id': 'u2',\n",
              "   'character': 'CAMERON',\n",
              "   'line_id': 'L1044',\n",
              "   'movie_id': 'm0',\n",
              "   'text': 'They do to!\\n'}),\n",
              " ('L985',\n",
              "  {'characted_id': 'u0',\n",
              "   'character': 'BIANCA',\n",
              "   'line_id': 'L985',\n",
              "   'movie_id': 'm0',\n",
              "   'text': 'I hope so.\\n'}),\n",
              " ('L984',\n",
              "  {'characted_id': 'u2',\n",
              "   'character': 'CAMERON',\n",
              "   'line_id': 'L984',\n",
              "   'movie_id': 'm0',\n",
              "   'text': 'She okay?\\n'}),\n",
              " ('L925',\n",
              "  {'characted_id': 'u0',\n",
              "   'character': 'BIANCA',\n",
              "   'line_id': 'L925',\n",
              "   'movie_id': 'm0',\n",
              "   'text': \"Let's go.\\n\"})]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pf64bVjkKJA"
      },
      "source": [
        "def load_conversations(file_name, lines):\n",
        "  conversations = []\n",
        "  \n",
        "  with open(file_name, 'r', encoding='iso-8859-1') as f:\n",
        "    for line in f:\n",
        "      values = line.split(' +++$+++ ')\n",
        "\n",
        "      coversation = {}\n",
        "      for i, field in enumerate(['character_1_id', 'character_2_id', 'movie_id', 'lines']):\n",
        "        coversation[field] = values[i]\n",
        "\n",
        "      line_ids = re.compile('L[0-9]+').findall(coversation['lines'])\n",
        "      coversation['lines'] = [lines[id]['text'] for id in line_ids]\n",
        "\n",
        "      conversations.append(coversation)\n",
        "      \n",
        "  return conversations"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tZXVtEnlNQT",
        "outputId": "ef4b4470-0b40-4b8c-a204-12a36e756e86"
      },
      "source": [
        "conversations = load_conversations('data/movie_conversations.txt', lines)\n",
        "conversations[:5]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'character_1_id': 'u0',\n",
              "  'character_2_id': 'u2',\n",
              "  'lines': ['Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\n',\n",
              "   \"Well, I thought we'd start with pronunciation, if that's okay with you.\\n\",\n",
              "   'Not the hacking and gagging and spitting part.  Please.\\n',\n",
              "   \"Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\\n\"],\n",
              "  'movie_id': 'm0'},\n",
              " {'character_1_id': 'u0',\n",
              "  'character_2_id': 'u2',\n",
              "  'lines': [\"You're asking me out.  That's so cute. What's your name again?\\n\",\n",
              "   'Forget it.\\n'],\n",
              "  'movie_id': 'm0'},\n",
              " {'character_1_id': 'u0',\n",
              "  'character_2_id': 'u2',\n",
              "  'lines': [\"No, no, it's my fault -- we didn't have a proper introduction ---\\n\",\n",
              "   'Cameron.\\n',\n",
              "   \"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\n\",\n",
              "   'Seems like she could get a date easy enough...\\n'],\n",
              "  'movie_id': 'm0'},\n",
              " {'character_1_id': 'u0',\n",
              "  'character_2_id': 'u2',\n",
              "  'lines': ['Why?\\n',\n",
              "   'Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\\n',\n",
              "   \"That's a shame.\\n\"],\n",
              "  'movie_id': 'm0'},\n",
              " {'character_1_id': 'u0',\n",
              "  'character_2_id': 'u2',\n",
              "  'lines': ['Gosh, if only we could find Kat a boyfriend...\\n',\n",
              "   'Let me see what I can do.\\n'],\n",
              "  'movie_id': 'm0'}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNYZ4I93_4AT"
      },
      "source": [
        "# https://stackoverflow.com/a/518232/2809427\n",
        "# usuwanie diakrytyków\n",
        "\n",
        "def to_ascii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyPqPyDf_40T"
      },
      "source": [
        "def normalize(s):\n",
        "    s = to_ascii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
        "    return s"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM3FlWzfrDTY"
      },
      "source": [
        "def extract_pairs(conversations):\n",
        "  pairs = []\n",
        "  \n",
        "  for conversation in conversations:\n",
        "    for i in range(len(conversation['lines']) - 1):\n",
        "      q_line = normalize(conversation['lines'][i].strip())\n",
        "      a_line = normalize(conversation['lines'][i + 1].strip())\n",
        "      \n",
        "      if q_line and a_line:\n",
        "        pairs.append([q_line, a_line])\n",
        "\n",
        "  return pairs"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsPBiV9VsiwV",
        "outputId": "79c43ff6-f91f-4514-e6b3-f0338f7df21d"
      },
      "source": [
        "pairs = extract_pairs(conversations)\n",
        "pairs[:5]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['can we make this quick ? roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad . again .',\n",
              "  'well i thought we d start with pronunciation if that s okay with you .'],\n",
              " ['well i thought we d start with pronunciation if that s okay with you .',\n",
              "  'not the hacking and gagging and spitting part . please .'],\n",
              " ['not the hacking and gagging and spitting part . please .',\n",
              "  'okay . . . then how bout we try out some french cuisine . saturday ? night ?'],\n",
              " ['you re asking me out . that s so cute . what s your name again ?',\n",
              "  'forget it .'],\n",
              " ['no no it s my fault we didn t have a proper introduction', 'cameron .']]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saYwQpmLeZs4"
      },
      "source": [
        "# musimy ograniczyć nieco nasz zbiór, dlatego interesują nas dialogi, które mają w sobvie nie więcej niż MAX_LENGTH słów.\n",
        "\n",
        "MAX_LENGTH = 10\n",
        "\n",
        "def filter_pair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "def filter_pairs(pairs):\n",
        "    return [pair for pair in pairs if filter_pair(pair)]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIZfU1RHfpen",
        "outputId": "910b360b-7a08-4ce8-fc33-ada8c48e2865"
      },
      "source": [
        "# i tworzymy pary dialogowe\n",
        "\n",
        "pairs = filter_pairs(pairs)\n",
        "pairs[:5]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['there .', 'where ?'],\n",
              " ['you have my word . as a gentleman', 'you re sweet .'],\n",
              " ['hi .', 'looks like things worked out tonight huh ?'],\n",
              " ['you know chastity ?', 'i believe we share an art instructor'],\n",
              " ['have fun tonight ?', 'tons']]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYmsLdrO5npk"
      },
      "source": [
        "# tokeny dla słowa ktore nie znajduje się w słowniku (o tym troche niżej) PAD\n",
        "# dla rozpoczęcia wypowiedzi SOS\n",
        "# dla zakończenia wypowiedzi EOS\n",
        "\n",
        "PAD_token = 0\n",
        "SOS_token = 1\n",
        "EOS_token = 2"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgXjzQDvBfeU"
      },
      "source": [
        "# tworzymy słownik (wszystkich słow występujących w naszych odifltrowanych dialogach)\n",
        "# w środku znajduje się licznik słów (ile razy dane słowo wystąpiło w korpusie)\n",
        "\n",
        "class Vocabulary:\n",
        "    def __init__(self):\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.num_words = 3\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.add_word(word)\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.num_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.num_words] = word\n",
        "            self.num_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "    def trim(self, min_count):\n",
        "        keep_words = []\n",
        "        for k, v in self.word2count.items():\n",
        "            if v >= min_count:\n",
        "                keep_words.append(k)\n",
        "\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.num_words = 3\n",
        "\n",
        "        for word in keep_words:\n",
        "            self.add_word(word)\n",
        "\n",
        "    def get_index(self, word):\n",
        "        if word not in self.word2index:\n",
        "            return PAD_token\n",
        "        else:\n",
        "            return self.word2index[word]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZRPg9yCBWmL"
      },
      "source": [
        "# question vocabulary vs answer vocabulary\n",
        "# slownik pytan i odpowiedzi\n",
        "\n",
        "qvoc = Vocabulary()\n",
        "avoc = Vocabulary()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "po_D8RSUBSlb",
        "outputId": "cfec5bee-1b7a-4e35-acd2-9a2c10f17653"
      },
      "source": [
        "# zobaczmy jak wyglądają słowniki (ile mają słów po załadowaniu)\n",
        "for pair in pairs:\n",
        "  qvoc.add_sentence(pair[0])\n",
        "  avoc.add_sentence(pair[1])\n",
        "\n",
        "print(qvoc.num_words)\n",
        "print(avoc.num_words)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14297\n",
            "13898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGfGWf6TYJz3",
        "outputId": "f0a3a7cf-419b-455f-987a-0ec3fd301178"
      },
      "source": [
        "qvoc.trim(3)\n",
        "avoc.trim(3)\n",
        "\n",
        "print(qvoc.num_words)\n",
        "print(avoc.num_words)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4930\n",
            "4742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRMN5gIESd9R"
      },
      "source": [
        "def sentence_to_tensor(voc, sentence):\n",
        "   indexes = [voc.get_index(word) for word in sentence.split(' ')]\n",
        "   indexes.append(EOS_token)\n",
        "\n",
        "   return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def pair_to_tensor(qvoc, avoc, pair):\n",
        "   input = sentence_to_tensor(qvoc, pair[0])\n",
        "   output = sentence_to_tensor(avoc, pair[1])\n",
        "\n",
        "   return (input, output)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzhZ764nTE8D",
        "outputId": "e9199e68-412c-4e04-9f77-eb11b01a666f"
      },
      "source": [
        "pair = random.choice(pairs)\n",
        "(input, output) = pair_to_tensor(qvoc, avoc, pair)\n",
        "\n",
        "print(input)\n",
        "print(output)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 48],\n",
            "        [  0],\n",
            "        [ 40],\n",
            "        [194],\n",
            "        [ 79],\n",
            "        [  5],\n",
            "        [400],\n",
            "        [ 14],\n",
            "        [  2]], device='cuda:0')\n",
            "tensor([[  18],\n",
            "        [ 174],\n",
            "        [ 524],\n",
            "        [2656],\n",
            "        [ 848],\n",
            "        [  18],\n",
            "        [   6],\n",
            "        [ 132],\n",
            "        [   8],\n",
            "        [   2]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEBoRJfBUFYz"
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyz1GK74UiiB"
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden, None\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuyvA7e-YqLZ"
      },
      "source": [
        "def step(input, target, encoder, decoder, enopt, deopt, criterion, max_length = MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    enopt.zero_grad()\n",
        "    deopt.zero_grad()\n",
        "\n",
        "    input_length = input.size(0)\n",
        "    target_length = target.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    for di in range(target_length):\n",
        "        decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "        loss += criterion(decoder_output, target[di])\n",
        "        decoder_input = target[di]\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), 50)\n",
        "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), 50)\n",
        "\n",
        "    enopt.step()\n",
        "    deopt.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTSLdzoPXxah"
      },
      "source": [
        "def train(name, encoder, decoder, qvoc, avoc, pairs, iterations = 100000, milestone = 5000):\n",
        "\n",
        "  # optymalizator\n",
        "  encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.0001)\n",
        "  decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.0001)\n",
        "  \n",
        "  # negative log likelihood loss\n",
        "  loss_fn = nn.NLLLoss()\n",
        "  avg_loss = 0\n",
        "\n",
        "  # losujemy pary treningowe\n",
        "  training_pairs = [pair_to_tensor(qvoc, avoc, random.choice(pairs)) for i in range(iterations)]\n",
        "  \n",
        "  for i in range(1, iterations):\n",
        "    input = training_pairs[i][0]\n",
        "    target = training_pairs[i][1]\n",
        "    \n",
        "    # dla kazdej pary treningowej szacujemy blad i sumujemy\n",
        "    loss = step(input, target, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_fn)\n",
        "    avg_loss += loss\n",
        "    \n",
        "    # uczymy korzystając z średniej na 5000 par (milestone)\n",
        "    if i % milestone == 0:\n",
        "      avg_loss = avg_loss / milestone\n",
        "      print('%d %.4f' % (i, avg_loss))\n",
        "      avg_loss = 0\n",
        "\n",
        "      torch.save(encoder.state_dict(), '/content/' + name + '_encoder_it-' + str(i) + '.model')\n",
        "      torch.save(decoder.state_dict(), '/content/' + name + '_decoder_it-' + str(i) + '.model')"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lSZTbBgYDaU"
      },
      "source": [
        "embed_size = 512\n",
        "hidden_size = 1024\n",
        "num_layers = 1\n",
        "\n",
        "# tworzymy dwa modele\n",
        "encoder = EncoderRNN(qvoc.num_words, hidden_size).to(device)\n",
        "decoder = DecoderRNN(hidden_size, avoc.num_words).to(device)"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train('seq2seq_chatbot', encoder, decoder, qvoc, avoc, pairs)"
      ],
      "metadata": {
        "id": "c7Oj1JKpMjDT"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ1wkMUVnHbB"
      },
      "source": [
        "# zapisanie wytrenowanych modeli (encodera i decodera)\n",
        "\n",
        "torch.save(encoder, '/content/seq2seq_chatbot_encoder.model')\n",
        "torch.save(decoder, '/content/seq2seq_chatbot_decoder.model')"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://raw.githubusercontent.com/dotjabber/alk-nlp-intro/main/seq2seq_chatbot_encoder.model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJUwoz_KlUwi",
        "outputId": "36bd4ef8-be4e-4cd5-bd68-6ddcf0f8d0a6"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 43.2M  100 43.2M    0     0  46.3M      0 --:--:-- --:--:-- --:--:-- 46.2M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# załadowanie wytrenowanych modeli\n",
        "# można je pobrać stąd:\n",
        "# encoder: https://raw.githubusercontent.com/dotjabber/alk-nlp-intro/main/seq2seq_chatbot_encoder.model\n",
        "# decoder: https://raw.githubusercontent.com/dotjabber/alk-nlp-intro/main/seq2seq_chatbot_decoder.model\n",
        "\n",
        "# !curl -O https://raw.githubusercontent.com/dotjabber/alk-nlp-intro/main/seq2seq_chatbot_encoder.model\n",
        "# !curl -O https://raw.githubusercontent.com/dotjabber/alk-nlp-intro/main/seq2seq_chatbot_decoder.model\n",
        "\n",
        "encoder = torch.load('/content/seq2seq_chatbot_encoder.model')\n",
        "decoder = torch.load('/content/seq2seq_chatbot_decoder.model')"
      ],
      "metadata": {
        "id": "BBYEqM_bKKrR"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWlmhsYhnK4w"
      },
      "source": [
        "def evaluate(encoder, decoder, qvoc, avoc, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = sentence_to_tensor(qvoc, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(avoc.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC42o0IsoSya",
        "outputId": "a6d65dcf-d3f6-4a06-b9e2-55a35572960b"
      },
      "source": [
        "evaluate(encoder, decoder, qvoc, avoc, 'hello')"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello', '.', '<EOS>']"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HKvEJ79Zh97X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}